<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>findMakerspace()</title>

  <!-- Font Awesome Icons -->
  <script src="https://kit.fontawesome.com/cdcc65decb.js" crossorigin="anonymous"></script>

  <!-- Prism CSS-->
  <link rel="stylesheet" type="text/css" href="styles/prism.css" />

  <!-- Prism JavaScript -->
  <script src="scripts/prism.js" defer></script>

  <!-- My CSS -->
  <link rel="stylesheet" type="text/css" href="styles/main.css" />
  <link rel="stylesheet" type="text/css" href="styles/nav.css" />
  <link rel="stylesheet" type="text/css" href="styles/about.css" />
</head>

<body>
  <nav id="navbar" class="navbar">

    <span id="nav-brand">
      <a href="/"> findMakerspace() </a>
    </span>

    <ul id="nav-menu">
      <li>
        <a href="about.html"> About </a>
      </li>
      <li>
        <a href="contact.html"> Contact </a>
      </li>
    </ul>
  </nav>

  <div id="page-header">
    <h1>About</h1>
  </div>

  <div id="page-content">
    <div id="about-description">
      <p>
        This site was created to be a fun tool to find US based makerspaces.
        The Python script below was used to do Google searches for a state name plus the word 'makerspace'
        and return a list of makerspace names along with their urls which was then saved to a json file.
      </p>

      <p>
        This JSON file was parsed to clean up names and verify websites. A map of the US was craeted as an SVG
        along with some JavaScript to make the interactive map on the main page.
      </p>

      <p>
        If interested, the code for this page can be found on Github.
      </p>

      <a href="https://github.com/makerinchief/find-makerspace" target="_blank">
        <i class="fa-brands fa-github"></i>
      </a>
    </div>

    <div id="about-code">
      <pre class="pre-scrollable">
        <code class="language-python">
  from requests import get
  from bs4 import BeautifulSoup
  import json
  from time import sleep

  state_list = [ 'state_name' ]

  maker_list = {}

  # Filter results to find only title and links.
  def filter_results(raw_html):
      soup = BeautifulSoup(raw_html, "html.parser")
      result_block = soup.find_all("div", attrs={"class": "g"})
      search_results = []
      for result in result_block:
          link = result.find("a", href=True)
          title = result.find("h3")
          if link and title:
              # print(f"FOUND:\nTITLE: {title.text} \nLINK: {link['href']}")
              arr = [title.text, link["href"]]
              search_results.append(arr)

      return search_results

  # Create a Google search url for a given state_name.
  # Then return the html from a url request.
  def search_google(state, num_results):
      user_agent = {
          "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "
          "Chrome/61.0.3163.100 Safari/537.36"
      }

      search_term = state + "+makerspace"
      google_url = "https://www.google.com/search?q={}&num={}&hl={}".format(
          search_term, num_results, "en"
      )

      response = get(google_url, headers=user_agent, proxies=None)
      response.raise_for_status()
      return response.text

  # Search all the states in the list.
  # Add the title and url to each state in the json file.
  for state in state_list:
      print(f"Finding spaces in {state}")
      state_spaces = filter_results(search_google(state, 25))
      maker_list[state] = state_spaces

      print(f"Saving {state} to JSON...")
      with open("./py-scripts/spaceList.json", "r+") as json_file:
          json.dump(maker_list, json_file)

      # Make sure to wait a few seconds between searches,
      # else Google will block your IP address for a bit.
      sleep(4)
        </code>
      </pre>
    </div>
  </div>
</body>

</html>